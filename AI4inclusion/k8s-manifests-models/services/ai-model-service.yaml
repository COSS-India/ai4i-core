apiVersion: apps/v1
kind: Deployment
metadata:
  name: ai-model-service
  namespace: default
  labels:
    app: ai-model-service
    workload-type: gpu
spec:
  replicas: 2
  selector:
    matchLabels:
      app: ai-model-service
  template:
    metadata:
      labels:
        app: ai-model-service
        workload-type: gpu
    spec:
      nodeSelector:
        node-type: gpu
      tolerations:
      - key: "nvidia.com/gpu"
        operator: "Exists"
        effect: "NoSchedule"
      containers:
      - name: ai-model-service
        image: nvidia/cuda:11.8-runtime-ubuntu22.04
        command: ["/bin/bash"]
        args:
        - -c
        - |
          apt-get update && apt-get install -y python3 python3-pip curl
          pip3 install flask requests
          cat > /app/app.py << 'EOF'
          from flask import Flask, request, jsonify
          import os
          
          app = Flask(__name__)
          
          @app.route('/health', methods=['GET'])
          def health():
              return jsonify({"status": "healthy", "service": "ai-model-service"})
          
          @app.route('/api/v1/ai-models', methods=['GET'])
          def list_models():
              return jsonify({
                  "models": [
                      {"id": "model-1", "name": "GPT-4", "status": "ready"},
                      {"id": "model-2", "name": "Claude-3", "status": "ready"},
                      {"id": "model-3", "name": "Llama-2", "status": "training"}
                  ]
              })
          
          @app.route('/api/v1/ai-models/<model_id>/predict', methods=['POST'])
          def predict(model_id):
              data = request.get_json()
              return jsonify({
                  "model_id": model_id,
                  "prediction": "Sample prediction result",
                  "input": data
              })
          
          if __name__ == '__main__':
              app.run(host='0.0.0.0', port=8080)
          EOF
          python3 /app/app.py
        ports:
        - containerPort: 8080
        resources:
          requests:
            nvidia.com/gpu: 1
            cpu: 500m
            memory: 1Gi
          limits:
            nvidia.com/gpu: 1
            cpu: 2000m
            memory: 4Gi
        livenessProbe:
          httpGet:
            path: /health
            port: 8080
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /health
            port: 8080
          initialDelaySeconds: 5
          periodSeconds: 5
---
apiVersion: v1
kind: Service
metadata:
  name: ai-model-service
  namespace: default
  labels:
    app: ai-model-service
spec:
  type: ClusterIP
  ports:
  - port: 8080
    targetPort: 8080
    protocol: TCP
  selector:
    app: ai-model-service
