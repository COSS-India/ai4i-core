# LLM Service Environment Configuration Template
# Copy this file to .env and update the values as needed

# Service Configuration
SERVICE_NAME=llm-service
SERVICE_PORT=8090
LOG_LEVEL=INFO

# PostgreSQL Configuration
DATABASE_URL=postgresql+asyncpg://dhruva_user:dhruva_secure_password_2024@postgres:5432/auth_db
DB_POOL_SIZE=20
DB_MAX_OVERFLOW=10

# Redis Configuration
REDIS_HOST=redis
REDIS_PORT=6379
REDIS_PASSWORD=redis_secure_password_2024

# Triton Inference Server Configuration
TRITON_ENDPOINT=http://13.220.11.146:8000
TRITON_API_KEY=your_triton_api_key_here
TRITON_TIMEOUT=300
TRITON_CONCURRENCY=20

# LLM Service Configuration
MAX_BATCH_SIZE=100
MAX_TEXT_LENGTH=50000
DEFAULT_INPUT_LANGUAGE=en
DEFAULT_OUTPUT_LANGUAGE=en

# Supported Languages (comma-separated)
SUPPORTED_LANGUAGES=en,hi,ta,te,kn,ml,bn,gu,mr,pa,or,as,ur

# Authentication Configuration
AUTH_ENABLED=true
API_KEY_CACHE_TTL=300
SESSION_TIMEOUT_SECONDS=3600

# Rate Limiting Configuration
RATE_LIMIT_ENABLED=true
RATE_LIMIT_PER_MINUTE=60
RATE_LIMIT_PER_HOUR=1000
RATE_LIMIT_PER_DAY=10000

# Security Configuration
ALLOW_ANONYMOUS_ACCESS=false
REQUIRE_API_KEY=true

